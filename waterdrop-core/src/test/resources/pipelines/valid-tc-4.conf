spark {

}

pipeline<p1> {
  input {
    fileStream {
      path = "/tmp/waterdrop/stream1"
    }
  }

  filter {
    sql {
      table_name = "t1"
      sql = "select * from t1 where raw_message <> 't1,3'"
    }
  }
  output {
    stdout {}
  }
}

pipeline<p2> {
  input {
    fileStream {
      path = "/tmp/waterdrop/stream2"
    }
  }

  filter {
    split {
      delimiter = ","
      fields = ["key", "value"]
    }
  }
  output {
    stdout {}
  }
}


