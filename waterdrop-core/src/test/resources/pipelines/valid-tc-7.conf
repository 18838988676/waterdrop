# batch processing
spark {

}

pipeline<p1> {
  input {
    file {
      path = "/tmp/waterdrop/batch1"
      format = "csv"
      table_name = "t1"
      options.header = true
    }
  }

  filter {
    sql {
      sql = "select * from t1"
    }
  }
  output {
    stdout {}
  }
}

pipeline<p2> {
  input {
    file {
      path = "/tmp/waterdrop/batch2"
      format = "csv"
      table_name = "t2"
      options.header = true
    }
  }

  filter {
    split {
      source_field = "value"
      delimiter = "-"
      fields = ["part1", "part2"]
    }
  }
  output {
    stdout {}
  }
}


